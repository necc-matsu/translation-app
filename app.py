import streamlit as st
import pandas as pd
import re
import json
from unidecode import unidecode
import os
import deepl
import io
from pathlib import Path
import zipfile

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆåˆæœŸå€¤ã¯ç©ºã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
manual_cache = {}
auto_cache = {}

def load_cache_from_file(file) -> tuple[dict, dict]:
    try:
        cache = json.load(file)
        manual = cache.get("manual", {})
        auto = cache.get("auto", {})
        return manual, auto
    except Exception as e:
        st.error(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return {}, {}

def save_cache(manual_cache, auto_cache, path: Path):
    with open(path, "w", encoding="utf-8") as f:
        json.dump({"manual": manual_cache, "auto": auto_cache}, f, ensure_ascii=False, indent=2)

def normalize_brackets(text):
    return text.replace("(", "ï¼ˆ").replace(")", "ï¼‰")

def japanese_to_romaji(text):
    return unidecode(text)

def clean_text(text):
    text = re.sub(r'[\x00-\x1F\x7F]', '', text)
    text = re.sub(r'[\r\n\t]', ' ', text)
    text = re.sub(r'[^\u3040-\u30FF\u4E00-\u9FFFa-zA-Z0-9\sï¼ˆï¼‰.,\-ï¼‹()ãƒ»]', '', text)
    return text.strip()

def translate_text(text, translator, manual_cache, auto_cache):
    if text is None or (isinstance(text, float) and pd.isna(text)):
        return ""
    text = str(text).strip()
    if text == "":
        return ""

    text = normalize_brackets(text)
    text = text.replace("â„ƒ", "C")

    for jp, en in manual_cache.items():
        text = text.replace(jp, en)

    japanese_parts = re.findall(r'[\u3040-\u30FF\u4E00-\u9FFF]+', text)

    for jp in japanese_parts:
        jp = clean_text(jp)
        if not jp:
            continue
        if len(jp.encode("utf-8")) > 4500:
            st.warning(f"ç¿»è¨³ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé•·ã™ãï¼‰: {jp[:50]}...")
            en = japanese_to_romaji(jp)
            auto_cache[jp] = en
            continue

        if jp in auto_cache:
            en = auto_cache[jp]
        else:
            try:
                result = translator.translate_text(jp, source_lang="JA", target_lang="EN-US")
                en = result.text
                auto_cache[jp] = en
            except Exception as e:
                st.error(f"DeepLç¿»è¨³ã‚¨ãƒ©ãƒ¼: '{jp}' â†’ ä¾‹å¤–: {e}")
                en = japanese_to_romaji(jp)
                auto_cache[jp] = en

        text = text.replace(jp, en)

    remaining = re.findall(r'[\u3040-\u30FF\u4E00-\u9FFF]+', text)
    for jp in remaining:
        text = text.replace(jp, japanese_to_romaji(jp))

    # æœ€å¾Œã« / ã‚’ _ ã«å¤‰æ›
    text = text.replace("/", "_")

    # ä¸¸æ•°å­—ã‚’ _1, _2, ... ã«å¤‰æ›
    maru_map = {
        "â‘ ": "_1", "â‘¡": "_2", "â‘¢": "_3", "â‘£": "_4", "â‘¤": "_5",
        "â‘¥": "_6", "â‘¦": "_7", "â‘§": "_8", "â‘¨": "_9", "â‘©": "_10",
        "â‘ª": "_11", "â‘«": "_12", "â‘¬": "_13", "â‘­": "_14", "â‘®": "_15"
    }
    for maru, repl in maru_map.items():
        text = text.replace(maru, repl)

    return text

def main():
    st.title("ã‚µãƒ³ãƒ—ãƒ«åå¤‰æ› (æ—¥æœ¬èªâ†’è‹±èª)")
    st.write("â€»ãƒ•ã‚¡ã‚¤ãƒ«åã¯è‹±æ•°å­—ã®ã¿ã«ã—ã¦ãã ã•ã„ã€‚ã€Œã‚µãƒ³ãƒ—ãƒ«åã€ã‚’å«ã‚€åˆ—ã®ã¿å¤‰æ›ã—ã¾ã™ã€‚")
    
    global manual_cache, auto_cache

    st.sidebar.info("æœ€åˆã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥(JSONãƒ•ã‚¡ã‚¤ãƒ«)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    cache_file = st.sidebar.file_uploader("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«(JSON)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["json"])
    if cache_file is not None:
        manual_cache, auto_cache = load_cache_from_file(cache_file)
        st.sidebar.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

    DEEPL_API_KEY = st.secrets.get("DEEPL_API_KEY")
    if not DEEPL_API_KEY:
        st.error("DEEPL_API_KEYãŒSecretsã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.stop()

    translator = deepl.Translator(DEEPL_API_KEY)

    uploaded_file = st.file_uploader("ç¿»è¨³ã™ã‚‹Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["xlsx", "xls", "xlsm"])
    if not uploaded_file:
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ç¿»è¨³å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        return

    try:
        df = pd.read_excel(io.BytesIO(uploaded_file.read()), engine="openpyxl")
    except Exception as e:
        st.error(f"Excelãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    st.dataframe(df.head())

    target_col = "ã‚µãƒ³ãƒ—ãƒ«å"
    if target_col not in df.columns:
        st.error(f"åˆ— '{target_col}' ãŒãƒ•ã‚¡ã‚¤ãƒ«ã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        return

    texts_to_translate = df[target_col].dropna().unique().tolist()

    if st.button("ç¿»è¨³ã‚’å®Ÿè¡Œ"):

        translated_map = {}
        for text in texts_to_translate:
            translated_map[text] = translate_text(text, translator, manual_cache, auto_cache)

        df["è‹±èªå"] = df[target_col].map(translated_map)

        # ä¸Šæ›¸ãä¿å­˜: å…ƒã®Excelãƒ•ã‚¡ã‚¤ãƒ«åã« _translated ã‚’è¿½åŠ 
        output_excel_name = uploaded_file.name.rsplit(".", 1)[0] + "_translated.xlsx"
        df.to_excel(output_excel_name, index=False, engine="openpyxl")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚åŒã˜å ´æ‰€ã«ä¿å­˜ï¼ˆãŸã ã—ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒªãƒƒãƒˆç’°å¢ƒã§ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ä¸å®‰å®šï¼‰
        cache_save_path = Path(output_excel_name).parent / "translation_cache.json"
        try:
            save_cache(manual_cache, auto_cache, cache_save_path)
        except Exception as e:
            st.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        st.toast("ç¿»è¨³ãŒå®Œäº†ã—ã¾ã—ãŸã€‚", icon="âœ…")
       
        # ç¿»è¨³ã•ã‚ŒãŸçµæœã‚’ç”»é¢ã«è¡¨ç¤ºï¼ˆè¿½åŠ ï¼‰
        st.write("ç¿»è¨³å¾Œã®Excelãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ZIPä½œæˆï¼ˆExcelã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã¾ã¨ã‚ã¦ï¼‰
        with io.BytesIO() as buffer:
            with zipfile.ZipFile(buffer, "w") as zipf:
                # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒˆåŒ–ã—ã¦ZIPã«è¿½åŠ 
                excel_bytes = io.BytesIO()
                df.to_excel(excel_bytes, index=False, engine="openpyxl")
                zipf.writestr(output_excel_name, excel_bytes.getvalue())

                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥JSONã‚’æ–‡å­—åˆ—åŒ–ã—ã¦ZIPã«è¿½åŠ 
                cache_json_str = json.dumps({"manual": manual_cache, "auto": auto_cache}, ensure_ascii=False, indent=2)
                zipf.writestr("translation_cache.json", cache_json_str)

            buffer.seek(0)
            st.download_button(
                label="ç¿»è¨³æ¸ˆã¿Excelã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=buffer,
                file_name="translated_and_cache.zip",
                mime="application/zip"
            )

            # è‹±èªåã®ã¿ã‚’ã‚³ãƒ”ãƒ¼ã§ãã‚‹ã‚ˆã†ã«ãƒœã‚¿ãƒ³ã§æä¾›ï¼ˆ1ã‚¯ãƒªãƒƒã‚¯ã‚³ãƒ”ãƒ¼ï¼‰
        if "è‹±èªå" in df.columns:
            english_names = df["è‹±èªå"].dropna().astype(str).tolist()
            english_text = "\n".join(english_names).replace("`", "\\`")  # JSã‚¨ãƒ©ãƒ¼å›é¿ç”¨

            st.markdown("#### ğŸ“‹ è‹±èªåãƒªã‚¹ãƒˆã®ã‚³ãƒ”ãƒ¼")
            st.text_area("ã‚³ãƒ”ãƒ¼å¯¾è±¡", english_text, height=200)

            copy_button = f"""
            <button 
                onclick="navigator.clipboard.writeText(`{english_text}`); 
                         alert('è‹±èªåãƒªã‚¹ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼');"
                style="
                    background-color: #4CAF50;
                    color: white;
                    padding: 10px 16px;
                    font-size: 16px;
                    border: none;
                    border-radius: 6px;
                    cursor: pointer;
                    margin-top: 10px;
                ">
                âœ… ã‚¯ãƒªãƒƒã‚¯ã—ã¦è‹±èªåã‚’ã‚³ãƒ”ãƒ¼
            </button>
            """
            st.markdown(copy_button, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
